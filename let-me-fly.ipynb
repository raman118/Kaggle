{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":105399,"databundleVersionId":12733338,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ramanofthesky/let-me-fly?scriptVersionId=246784320\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install lightgbm\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nimport tarfile\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestRegressor\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Install required packages if needed\n!pip install pyarrow\n\n# Load the parquet files\ntrain_df = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/train.parquet')\nsample_submission = pd.read_parquet('/kaggle/input/aeroclub-recsys-2025/sample_submission.parquet')\n\nprint(\"Train shape:\", train_df.shape)\nprint(\"Sample submission shape:\", sample_submission.shape)\nprint(\"\\nTrain columns:\", train_df.columns.tolist())\nprint(\"Sample submission columns:\", sample_submission.columns.tolist())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:33:47.117468Z","iopub.execute_input":"2025-06-22T09:33:47.118514Z","iopub.status.idle":"2025-06-22T09:34:25.818637Z","shell.execute_reply.started":"2025-06-22T09:33:47.118486Z","shell.execute_reply":"2025-06-22T09:34:25.812604Z"}},"outputs":[{"name":"stdout","text":"Collecting lightgbm\n  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/site-packages (from lightgbm) (2.0.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from lightgbm) (1.15.2)\nInstalling collected packages: lightgbm\nSuccessfully installed lightgbm-4.6.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/site-packages (20.0.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nTrain shape: (18145372, 126)\nSample submission shape: (6897776, 3)\n\nTrain columns: ['Id', 'bySelf', 'companyID', 'corporateTariffCode', 'frequentFlyer', 'nationality', 'isAccess3D', 'isVip', 'legs0_arrivalAt', 'legs0_departureAt', 'legs0_duration', 'legs0_segments0_aircraft_code', 'legs0_segments0_arrivalTo_airport_city_iata', 'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_baggageAllowance_quantity', 'legs0_segments0_baggageAllowance_weightMeasurementType', 'legs0_segments0_cabinClass', 'legs0_segments0_departureFrom_airport_iata', 'legs0_segments0_duration', 'legs0_segments0_flightNumber', 'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code', 'legs0_segments0_seatsAvailable', 'legs0_segments1_aircraft_code', 'legs0_segments1_arrivalTo_airport_city_iata', 'legs0_segments1_arrivalTo_airport_iata', 'legs0_segments1_baggageAllowance_quantity', 'legs0_segments1_baggageAllowance_weightMeasurementType', 'legs0_segments1_cabinClass', 'legs0_segments1_departureFrom_airport_iata', 'legs0_segments1_duration', 'legs0_segments1_flightNumber', 'legs0_segments1_marketingCarrier_code', 'legs0_segments1_operatingCarrier_code', 'legs0_segments1_seatsAvailable', 'legs0_segments2_aircraft_code', 'legs0_segments2_arrivalTo_airport_city_iata', 'legs0_segments2_arrivalTo_airport_iata', 'legs0_segments2_baggageAllowance_quantity', 'legs0_segments2_baggageAllowance_weightMeasurementType', 'legs0_segments2_cabinClass', 'legs0_segments2_departureFrom_airport_iata', 'legs0_segments2_duration', 'legs0_segments2_flightNumber', 'legs0_segments2_marketingCarrier_code', 'legs0_segments2_operatingCarrier_code', 'legs0_segments2_seatsAvailable', 'legs0_segments3_aircraft_code', 'legs0_segments3_arrivalTo_airport_city_iata', 'legs0_segments3_arrivalTo_airport_iata', 'legs0_segments3_baggageAllowance_quantity', 'legs0_segments3_baggageAllowance_weightMeasurementType', 'legs0_segments3_cabinClass', 'legs0_segments3_departureFrom_airport_iata', 'legs0_segments3_duration', 'legs0_segments3_flightNumber', 'legs0_segments3_marketingCarrier_code', 'legs0_segments3_operatingCarrier_code', 'legs0_segments3_seatsAvailable', 'legs1_arrivalAt', 'legs1_departureAt', 'legs1_duration', 'legs1_segments0_aircraft_code', 'legs1_segments0_arrivalTo_airport_city_iata', 'legs1_segments0_arrivalTo_airport_iata', 'legs1_segments0_baggageAllowance_quantity', 'legs1_segments0_baggageAllowance_weightMeasurementType', 'legs1_segments0_cabinClass', 'legs1_segments0_departureFrom_airport_iata', 'legs1_segments0_duration', 'legs1_segments0_flightNumber', 'legs1_segments0_marketingCarrier_code', 'legs1_segments0_operatingCarrier_code', 'legs1_segments0_seatsAvailable', 'legs1_segments1_aircraft_code', 'legs1_segments1_arrivalTo_airport_city_iata', 'legs1_segments1_arrivalTo_airport_iata', 'legs1_segments1_baggageAllowance_quantity', 'legs1_segments1_baggageAllowance_weightMeasurementType', 'legs1_segments1_cabinClass', 'legs1_segments1_departureFrom_airport_iata', 'legs1_segments1_duration', 'legs1_segments1_flightNumber', 'legs1_segments1_marketingCarrier_code', 'legs1_segments1_operatingCarrier_code', 'legs1_segments1_seatsAvailable', 'legs1_segments2_aircraft_code', 'legs1_segments2_arrivalTo_airport_city_iata', 'legs1_segments2_arrivalTo_airport_iata', 'legs1_segments2_baggageAllowance_quantity', 'legs1_segments2_baggageAllowance_weightMeasurementType', 'legs1_segments2_cabinClass', 'legs1_segments2_departureFrom_airport_iata', 'legs1_segments2_duration', 'legs1_segments2_flightNumber', 'legs1_segments2_marketingCarrier_code', 'legs1_segments2_operatingCarrier_code', 'legs1_segments2_seatsAvailable', 'legs1_segments3_aircraft_code', 'legs1_segments3_arrivalTo_airport_city_iata', 'legs1_segments3_arrivalTo_airport_iata', 'legs1_segments3_baggageAllowance_quantity', 'legs1_segments3_baggageAllowance_weightMeasurementType', 'legs1_segments3_cabinClass', 'legs1_segments3_departureFrom_airport_iata', 'legs1_segments3_duration', 'legs1_segments3_flightNumber', 'legs1_segments3_marketingCarrier_code', 'legs1_segments3_operatingCarrier_code', 'legs1_segments3_seatsAvailable', 'miniRules0_monetaryAmount', 'miniRules0_percentage', 'miniRules0_statusInfos', 'miniRules1_monetaryAmount', 'miniRules1_percentage', 'miniRules1_statusInfos', 'pricingInfo_isAccessTP', 'pricingInfo_passengerCount', 'profileId', 'ranker_id', 'requestDate', 'searchRoute', 'sex', 'taxes', 'totalPrice', 'selected']\nSample submission columns: ['Id', 'ranker_id', 'selected']\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tarfile\nimport json\nimport os\nimport gc\n\n# Don't extract all files at once - process them one by one\ndef process_json_tar_efficiently(tar_path):\n    \"\"\"\n    Process JSON files from tar archive without extracting all to disk\n    \"\"\"\n    all_json_data = []\n    \n    with tarfile.open(tar_path, 'r') as tar:\n        # Get list of JSON files in the archive\n        json_members = [member for member in tar.getmembers() if member.name.endswith('.json')]\n        print(f\"Found {len(json_members)} JSON files in archive\")\n        \n        # Process files in batches to manage memory\n        batch_size = 10  # Process 10 files at a time\n        \n        for i in range(0, len(json_members), batch_size):\n            batch = json_members[i:i+batch_size]\n            print(f\"Processing batch {i//batch_size + 1}/{(len(json_members)-1)//batch_size + 1}\")\n            \n            for member in batch:\n                try:\n                    # Extract file to memory, not disk\n                    f = tar.extractfile(member)\n                    if f is not None:\n                        content = f.read().decode('utf-8')\n                        data = json.loads(content)\n                        \n                        # Process the JSON data\n                        processed_data = process_single_json(data, member.name)\n                        if processed_data:\n                            all_json_data.append(processed_data)\n                        \n                        # Clean up\n                        f.close()\n                        del content, data\n                        \n                except Exception as e:\n                    print(f\"Error processing {member.name}: {e}\")\n                    continue\n            \n            # Force garbage collection after each batch\n            gc.collect()\n            \n            # Stop after processing enough files for feature extraction\n            if len(all_json_data) >= 1000:  # Adjust this number based on your needs\n                print(f\"Processed {len(all_json_data)} files, stopping to save memory\")\n                break\n    \n    return all_json_data\n\ndef process_single_json(data, filename):\n    \"\"\"\n    Extract features from a single JSON object\n    Customize this based on your JSON structure\n    \"\"\"\n    try:\n        processed = {\n            'filename': filename,\n        }\n        \n        # Add feature extraction based on your JSON structure\n        if isinstance(data, dict):\n            # Example feature extractions - adjust based on your data\n            processed['num_keys'] = len(data.keys())\n            \n            # Common RecSys features\n            if 'user_id' in data:\n                processed['user_id'] = data['user_id']\n            if 'item_id' in data:\n                processed['item_id'] = data['item_id']\n            if 'rating' in data:\n                processed['rating'] = data['rating']\n            if 'timestamp' in data:\n                processed['timestamp'] = data['timestamp']\n            if 'interactions' in data:\n                processed['num_interactions'] = len(data['interactions']) if isinstance(data['interactions'], list) else 1\n            \n        return processed\n        \n    except Exception as e:\n        print(f\"Error processing JSON {filename}: {e}\")\n        return None\n\n# Process the JSON files efficiently\njson_data = process_json_tar_efficiently('/kaggle/input/aeroclub-recsys-2025/jsons_raw.tar.kaggle')\njson_df = pd.DataFrame(json_data)\n\nprint(f\"Extracted features from {len(json_df)} JSON files\")\nif not json_df.empty:\n    print(\"JSON DataFrame shape:\", json_df.shape)\n    print(\"JSON DataFrame columns:\", json_df.columns.tolist())\n    print(json_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:35:51.056145Z","iopub.execute_input":"2025-06-22T09:35:51.056532Z","iopub.status.idle":"2025-06-22T09:39:10.616521Z","shell.execute_reply.started":"2025-06-22T09:35:51.056496Z","shell.execute_reply":"2025-06-22T09:39:10.610636Z"}},"outputs":[{"name":"stdout","text":"Found 150770 JSON files in archive\nProcessing batch 1/15077\nProcessing batch 2/15077\nProcessing batch 3/15077\nProcessing batch 4/15077\nProcessing batch 5/15077\nProcessing batch 6/15077\nProcessing batch 7/15077\nProcessing batch 8/15077\nProcessing batch 9/15077\nProcessing batch 10/15077\nProcessing batch 11/15077\nProcessing batch 12/15077\nProcessing batch 13/15077\nProcessing batch 14/15077\nProcessing batch 15/15077\nProcessing batch 16/15077\nProcessing batch 17/15077\nProcessing batch 18/15077\nProcessing batch 19/15077\nProcessing batch 20/15077\nProcessing batch 21/15077\nProcessing batch 22/15077\nProcessing batch 23/15077\nProcessing batch 24/15077\nProcessing batch 25/15077\nProcessing batch 26/15077\nProcessing batch 27/15077\nProcessing batch 28/15077\nProcessing batch 29/15077\nProcessing batch 30/15077\nProcessing batch 31/15077\nProcessing batch 32/15077\nProcessing batch 33/15077\nProcessing batch 34/15077\nProcessing batch 35/15077\nProcessing batch 36/15077\nProcessing batch 37/15077\nProcessing batch 38/15077\nProcessing batch 39/15077\nProcessing batch 40/15077\nProcessing batch 41/15077\nProcessing batch 42/15077\nProcessing batch 43/15077\nProcessing batch 44/15077\nProcessing batch 45/15077\nProcessing batch 46/15077\nProcessing batch 47/15077\nProcessing batch 48/15077\nProcessing batch 49/15077\nProcessing batch 50/15077\nProcessing batch 51/15077\nProcessing batch 52/15077\nProcessing batch 53/15077\nProcessing batch 54/15077\nProcessing batch 55/15077\nProcessing batch 56/15077\nProcessing batch 57/15077\nProcessing batch 58/15077\nProcessing batch 59/15077\nProcessing batch 60/15077\nProcessing batch 61/15077\nProcessing batch 62/15077\nProcessing batch 63/15077\nProcessing batch 64/15077\nProcessing batch 65/15077\nProcessing batch 66/15077\nProcessing batch 67/15077\nProcessing batch 68/15077\nProcessing batch 69/15077\nProcessing batch 70/15077\nProcessing batch 71/15077\nProcessing batch 72/15077\nProcessing batch 73/15077\nProcessing batch 74/15077\nProcessing batch 75/15077\nProcessing batch 76/15077\nProcessing batch 77/15077\nProcessing batch 78/15077\nProcessing batch 79/15077\nProcessing batch 80/15077\nProcessing batch 81/15077\nProcessing batch 82/15077\nProcessing batch 83/15077\nProcessing batch 84/15077\nProcessing batch 85/15077\nProcessing batch 86/15077\nProcessing batch 87/15077\nProcessing batch 88/15077\nProcessing batch 89/15077\nProcessing batch 90/15077\nProcessing batch 91/15077\nProcessing batch 92/15077\nProcessing batch 93/15077\nProcessing batch 94/15077\nProcessing batch 95/15077\nProcessing batch 96/15077\nProcessing batch 97/15077\nProcessing batch 98/15077\nProcessing batch 99/15077\nProcessing batch 100/15077\nProcessed 1000 files, stopping to save memory\nExtracted features from 1000 JSON files\nJSON DataFrame shape: (1000, 2)\nJSON DataFrame columns: ['filename', 'num_keys']\n                                    filename  num_keys\n0  raw/99d7fb3f49c642f0b4d45d2156271d56.json         7\n1  raw/53e6fdbd9d4f479699bfb13bcbe237fb.json         7\n2  raw/b960cbc710b64950b1d76d1f06ab7968.json         7\n3  raw/c32d0c08c12c49a4a274ca2e9bd7a6dd.json         7\n4  raw/84f9039d876d47648996bf8bdd288734.json         7\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Data Exploration and Understanding\nprint(\"=== TRAIN DATA EXPLORATION ===\")\nprint(train_df.head())\nprint(\"\\nTrain data info:\")\nprint(train_df.info())\nprint(\"\\nTrain data description:\")\nprint(train_df.describe())\n\nprint(\"\\n=== SAMPLE SUBMISSION EXPLORATION ===\")\nprint(sample_submission.head())\nprint(\"\\nSample submission info:\")\nprint(sample_submission.info())\n\n# Check for missing values\nprint(\"\\n=== MISSING VALUES ===\")\nprint(\"Train missing values:\")\nprint(train_df.isnull().sum())\nprint(\"\\nSample submission missing values:\")\nprint(sample_submission.isnull().sum())\n\n# Initialize extracted_files as empty list since extraction failed\nextracted_files = []\n\n# Try to explore JSON structure without extracting files\nprint(\"\\n=== JSON STRUCTURE EXPLORATION ===\")\ntry:\n    # Read the JSON structure documentation\n    with open('/kaggle/input/aeroclub-recsys-2025/jsons_structure.md', 'r') as f:\n        json_structure = f.read()\n    print(\"JSON Structure Documentation:\")\n    print(json_structure)\nexcept Exception as e:\n    print(f\"Could not read JSON structure file: {e}\")\n\n# Try to peek at one JSON file without extracting all\nprint(\"\\n=== SAMPLE JSON PEEK ===\")\ntry:\n    import tarfile\n    import json\n    \n    with tarfile.open('/kaggle/input/aeroclub-recsys-2025/jsons_raw.tar.kaggle', 'r') as tar:\n        # Get first JSON file\n        json_members = [member for member in tar.getmembers() if member.name.endswith('.json')]\n        if json_members:\n            first_json = json_members[0]\n            f = tar.extractfile(first_json)\n            if f is not None:\n                content = f.read().decode('utf-8')\n                sample_json = json.loads(content)\n                print(f\"Sample JSON file: {first_json.name}\")\n                print(f\"JSON keys: {list(sample_json.keys()) if isinstance(sample_json, dict) else 'Not a dictionary'}\")\n                print(f\"JSON structure preview: {str(sample_json)[:500]}...\")\n                f.close()\n        else:\n            print(\"No JSON files found in archive\")\n            \nexcept Exception as e:\n    print(f\"Could not peek at JSON files: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:41:10.992807Z","iopub.execute_input":"2025-06-22T09:41:10.993225Z","iopub.status.idle":"2025-06-22T09:44:28.30069Z","shell.execute_reply.started":"2025-06-22T09:41:10.993194Z","shell.execute_reply":"2025-06-22T09:44:28.295574Z"}},"outputs":[{"name":"stdout","text":"=== TRAIN DATA EXPLORATION ===\n   Id  bySelf  companyID  corporateTariffCode frequentFlyer  nationality  \\\n0   0    True      57323                 <NA>      S7/SU/UT           36   \n1   1    True      57323                  123      S7/SU/UT           36   \n2   2    True      57323                 <NA>      S7/SU/UT           36   \n3   3    True      57323                  123      S7/SU/UT           36   \n4   4    True      57323                 <NA>      S7/SU/UT           36   \n\n   isAccess3D  isVip      legs0_arrivalAt    legs0_departureAt  ...  \\\n0       False  False  2024-06-15T16:20:00  2024-06-15T15:40:00  ...   \n1        True  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n2       False  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n3        True  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n4       False  False  2024-06-15T14:50:00  2024-06-15T09:25:00  ...   \n\n  pricingInfo_isAccessTP pricingInfo_passengerCount profileId  \\\n0                    1.0                          1   2087645   \n1                    1.0                          1   2087645   \n2                    1.0                          1   2087645   \n3                    1.0                          1   2087645   \n4                    1.0                          1   2087645   \n\n                          ranker_id         requestDate    searchRoute   sex  \\\n0  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n1  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n2  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n3  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n4  98ce0dabf6964640b63079fbafd42cbe 2024-05-17 03:03:08  TLKKJA/KJATLK  True   \n\n    taxes totalPrice selected  \n0   370.0    16884.0        1  \n1  2240.0    51125.0        0  \n2  2240.0    53695.0        0  \n3  2240.0    81880.0        0  \n4  2240.0    86070.0        0  \n\n[5 rows x 126 columns]\n\nTrain data info:\n<class 'pandas.core.frame.DataFrame'>\nIndex: 18145372 entries, 0 to 18146431\nColumns: 126 entries, Id to selected\ndtypes: Int64(2), bool(4), datetime64[ns](1), float64(41), int64(5), object(73)\nmemory usage: 16.7+ GB\nNone\n\nTrain data description:\n                 Id     companyID  corporateTariffCode  nationality  \\\ncount  1.814537e+07  1.814537e+07            8911447.0   18145372.0   \nmean   9.072686e+06  4.729387e+04           107.084814    35.695906   \nmin    0.000000e+00  1.663600e+04                  0.0          0.0   \n25%    4.536343e+06  4.025300e+04                 66.0         36.0   \n50%    9.072686e+06  4.555500e+04                108.0         36.0   \n75%    1.360903e+07  5.866400e+04                153.0         36.0   \nmax    1.814643e+07  6.348200e+04                181.0         48.0   \nstd    5.238118e+06  1.211986e+04            46.395169     2.922091   \n\n       legs0_segments0_baggageAllowance_quantity  \\\ncount                               1.814431e+07   \nmean                                2.634662e+00   \nmin                                 0.000000e+00   \n25%                                 0.000000e+00   \n50%                                 1.000000e+00   \n75%                                 2.000000e+00   \nmax                                 6.000000e+01   \nstd                                 7.253907e+00   \n\n       legs0_segments0_baggageAllowance_weightMeasurementType  \\\ncount                                       1.814431e+07        \nmean                                        5.897866e-02        \nmin                                         0.000000e+00        \n25%                                         0.000000e+00        \n50%                                         0.000000e+00        \n75%                                         0.000000e+00        \nmax                                         1.000000e+00        \nstd                                         2.355848e-01        \n\n       legs0_segments0_cabinClass  legs0_segments0_seatsAvailable  \\\ncount                1.814537e+07                    1.806558e+07   \nmean                 1.212674e+00                    5.146003e+00   \nmin                  1.000000e+00                    1.000000e+00   \n25%                  1.000000e+00                    2.000000e+00   \n50%                  1.000000e+00                    5.000000e+00   \n75%                  1.000000e+00                    9.000000e+00   \nmax                  4.000000e+00                    1.000000e+01   \nstd                  4.891467e-01                    3.119127e+00   \n\n       legs0_segments1_baggageAllowance_quantity  \\\ncount                               3.798768e+06   \nmean                                8.072913e+00   \nmin                                 0.000000e+00   \n25%                                 1.000000e+00   \n50%                                 1.000000e+00   \n75%                                 2.000000e+00   \nmax                                 6.000000e+01   \nstd                                 1.348637e+01   \n\n       legs0_segments1_baggageAllowance_weightMeasurementType  ...  \\\ncount                                       3.798768e+06       ...   \nmean                                        2.388519e-01       ...   \nmin                                         0.000000e+00       ...   \n25%                                         0.000000e+00       ...   \n50%                                         0.000000e+00       ...   \n75%                                         0.000000e+00       ...   \nmax                                         1.000000e+00       ...   \nstd                                         4.263821e-01       ...   \n\n       miniRules1_monetaryAmount  miniRules1_percentage  \\\ncount               1.674963e+07          273882.000000   \nmean                1.348127e+03               3.000161   \nmin                 0.000000e+00               0.000000   \n25%                 0.000000e+00               0.000000   \n50%                 0.000000e+00               0.000000   \n75%                 2.800000e+03               0.000000   \nmax                 7.161273e+06              70.000000   \nstd                 5.944780e+03              10.848518   \n\n       miniRules1_statusInfos  pricingInfo_isAccessTP  \\\ncount            1.662720e+07            1.724033e+07   \nmean             5.806941e-01            4.988453e-01   \nmin              0.000000e+00            0.000000e+00   \n25%              0.000000e+00            0.000000e+00   \n50%              1.000000e+00            0.000000e+00   \n75%              1.000000e+00            1.000000e+00   \nmax              1.000000e+00            1.000000e+00   \nstd              4.934455e-01            4.999987e-01   \n\n       pricingInfo_passengerCount     profileId  \\\ncount                  18145372.0  1.814537e+07   \nmean                          1.0  2.494203e+06   \nmin                           1.0  8.130000e+02   \n25%                           1.0  1.843022e+06   \n50%                           1.0  2.814466e+06   \n75%                           1.0  3.301872e+06   \nmax                           1.0  3.604410e+06   \nstd                           0.0  9.503914e+05   \n\n                         requestDate         taxes    totalPrice      selected  \ncount                       18145372  1.814537e+07  1.814537e+07  1.814537e+07  \nmean   2024-08-19 12:44:59.654136064  4.284696e+03  4.631444e+04  5.816304e-03  \nmin              2024-05-17 03:03:08  0.000000e+00  7.700000e+02  0.000000e+00  \n25%              2024-07-16 08:14:32  1.006000e+03  1.289700e+04  0.000000e+00  \n50%              2024-08-27 09:07:56  1.246000e+03  2.497600e+04  0.000000e+00  \n75%              2024-09-26 11:49:57  1.746000e+03  5.510800e+04  0.000000e+00  \nmax              2024-10-29 12:48:50  8.979210e+05  9.944355e+06  1.000000e+00  \nstd                              NaN  1.183975e+04  7.506808e+04  7.604259e-02  \n\n[8 rows x 49 columns]\n\n=== SAMPLE SUBMISSION EXPLORATION ===\n                Id                         ranker_id  selected\n18144679  18144679  c9373e5f772e43d593dd6ad2fa90f67a       178\n18144680  18144680  c9373e5f772e43d593dd6ad2fa90f67a       363\n18144681  18144681  c9373e5f772e43d593dd6ad2fa90f67a       277\n18144682  18144682  c9373e5f772e43d593dd6ad2fa90f67a       183\n18144683  18144683  c9373e5f772e43d593dd6ad2fa90f67a        55\n\nSample submission info:\n<class 'pandas.core.frame.DataFrame'>\nIndex: 6897776 entries, 18144679 to 25043147\nData columns (total 3 columns):\n #   Column     Dtype \n---  ------     ----- \n 0   Id         int64 \n 1   ranker_id  object\n 2   selected   int64 \ndtypes: int64(2), object(1)\nmemory usage: 210.5+ MB\nNone\n\n=== MISSING VALUES ===\nTrain missing values:\nId                            0\nbySelf                        0\ncompanyID                     0\ncorporateTariffCode     9233925\nfrequentFlyer          12012727\n                         ...   \nsearchRoute                   0\nsex                           0\ntaxes                         0\ntotalPrice                    0\nselected                      0\nLength: 126, dtype: int64\n\nSample submission missing values:\nId           0\nranker_id    0\nselected     0\ndtype: int64\n\n=== JSON STRUCTURE EXPLORATION ===\nJSON Structure Documentation:\n# JSON Structure Documentation - FlightRank 2025\n\n## Top Level Structure\n\n```json\n{\n  \"$id\": \"string\",           // Service ID (optional)\n  \"metadata\": {...},         // Search metadata\n  \"personalData\": {...},     // User data\n  \"routeData\": {...},        // Route information\n  \"data\": {...},             // Flight options\n  \"ranker_id\": \"string\",     // Unique request ID\n  \"request_time\": \"string\"   // Request timestamp\n}\n```\n\n## metadata - Search Metadata\n\n```json\n{\n  \"$id\": \"string\",      // Service ID\n  \"searchType\": integer // Search type (0 or 1)\n}\n```\n\n## personalData - User Data\n\n```json\n{\n  \"$id\": \"string\",              // Service ID\n  \"profileId\": integer,         // User ID\n  \"sex\": boolean,               // Gender (true/false)\n  \"bySelf\": boolean,            // Self booking\n  \"yearOfBirth\": integer,       // Birth year\n  \"nationality\": integer,       // Nationality code\n  \"companyID\": integer,         // Company ID\n  \"isVip\": boolean,             // VIP status\n  \"hasAssistant\": boolean,      // Has assistant\n  \"isGlobal\": boolean,          // Global status\n  \"frequentFlyer\": string,      // Frequent flyer programs (e.g., \"SU/S7\")\n  \"position\": null,             // Position (usually null)\n  \"pointOfSale\": null,          // Point of sale (usually null)\n  \"industryEN\": null,           // Industry (usually null)\n  \"grade\": null                 // Grade (usually null)\n}\n```\n\n## routeData - Route Information\n\n```json\n{\n  \"$id\": \"string\",                    // Service ID\n  \"requestDate\": \"string\",            // Request date and time (ISO format)\n  \"searchRoute\": \"string\",            // Route in IATA codes format\n  \"requestDepartureDate\": \"string\",   // Desired departure date\n  \"requestReturnDate\": \"string\"       // Desired return date (null for one-way)\n}\n```\n\n### searchRoute Examples:\n- `\"OVBKHV/KHVOVB\"` - round trip (Novosibirsk ↔ Khabarovsk)\n- `\"MOWALA/ALAMOW\"` - round trip (Moscow ↔ Almaty)\n- `\"CEKMOW\"` - one way (Chelyabinsk → Moscow)\n\n## data - Flight Options\n\nData structure:\n```json\n{\n  \"$id\": \"string\",\n  \"$values\": [...]  // Array of flight options\n}\n```\n\n### Flight Option\n\n```json\n{\n  \"$id\": \"string\",                // Service ID\n  \"id\": \"string\",                 // Unique option ID\n  \"validatingCarrier\": \"string\",  // Validating carrier code\n  \"category\": integer,            // Ticket category (0, 1)\n  \"legs\": [...],                  // Flight legs (outbound/return)\n  \"pricings\": [...]               // Pricing options\n}\n```\n\n## legs[] - Flight Legs\n\nEach leg represents a direction (outbound or return):\n\n```json\n{\n  \"$id\": \"string\",\n  \"duration\": \"string\",           // Total duration (\"04:45:00\")\n  \"segments\": [...],              // Flight segments\n  \"departureAt\": \"string\",        // Departure time (ISO format)\n  \"arrivalAt\": \"string\",          // Arrival time (ISO format)\n  \"departureFrom\": {...},         // Departure airport\n  \"arrivalTo\": {...}              // Arrival airport\n}\n```\n\n### segments[] - Flight Segments\n\nEach segment is a separate flight:\n\n```json\n{\n  \"$id\": \"string\",\n  \"id\": \"string\",                 // Segment ID\n  \"departureAt\": \"string\",        // Departure time\n  \"arrivalAt\": \"string\",          // Arrival time\n  \"duration\": \"string\",           // Segment duration\n  \"flightNumber\": \"string\",       // Flight number\n  \"stopCount\": integer,           // Number of stops\n  \"aircraft\": {                   // Aircraft type\n    \"$id\": \"string\",\n    \"code\": \"string\"              // Aircraft code (\"321\", \"77W\", \"SU9\")\n  },\n  \"marketingCarrier\": {           // Marketing carrier\n    \"$id\": \"string\",\n    \"code\": \"string\",             // Airline code (\"SU\", \"S7\")\n    \"alliance\": {                 // Alliance (optional)\n      \"$id\": \"string\",\n      \"code\": \"string\"            // Alliance code (\"AEROFLOT\", \"EMIRATES\")\n    }\n  },\n  \"operatingCarrier\": {...},      // Operating carrier (similar structure)\n  \"departureFrom\": {...},         // Departure airport\n  \"arrivalTo\": {...},             // Arrival airport\n  \"transfer\": \"string\"            // Transfer time (if applicable)\n}\n```\n\n## Airport Structure\n\n```json\n{\n  \"$id\": \"string\",\n  \"airport\": {\n    \"$id\": \"string\",\n    \"id\": integer,                // Airport ID\n    \"code\": \"string\",             // Airport code\n    \"iata\": \"string\",             // IATA code (\"SVO\", \"LED\")\n    \"icao\": \"string\",             // ICAO code (\"UUEE\", \"UWGG\")\n    \"city\": {                     // City\n      \"$id\": \"string\",\n      \"id\": integer,              // City ID\n      \"code\": \"string\",           // City code\n      \"iata\": \"string\",           // City IATA code\n      \"country\": {                // Country\n        \"$id\": \"string\",\n        \"id\": integer,            // Country ID\n        \"codeA2\": \"string\",       // 2-letter code (\"RU\", \"KZ\")\n        \"codeA3\": \"string\"        // 3-letter code (\"RUS\", \"KAZ\")\n      }\n    }\n  },\n  \"terminal\": \"string\"            // Terminal (optional)\n}\n```\n\n## pricings[] - Pricing Options\n\n```json\n{\n  \"$id\": \"string\",\n  \"id\": \"string\",                         // Pricing option ID\n  \"totalPrice\": number,                   // Total price\n  \"taxes\": number,                        // Taxes and fees\n  \"timeLimit\": \"string\",                  // Booking time limit\n  \"supplierId\": \"string\",                 // Supplier ID\n  \"ordinal\": integer,                     // Order number\n  \"category\": integer,                    // Fare category\n  \"currencyCode\": \"string\",               // Currency code (\"RUB\", \"KZT\")\n  \"corporateTariffCode\": integer,         // Corporate tariff code (can be null)\n  \"isSegDiscountVariant\": boolean,        // Discount variant\n  \"isSegDiscountAsExactValue\": boolean,   // Discount as exact value\n  \"labels\": [...],                        // Option labels\n  \"miniRules\": [...],                     // Fare rules\n  \"pricingInfo\": [...],                   // Detailed pricing information\n  \"additionalData\": {...}                 // Additional data\n}\n```\n\n### labels[] - Option Labels\n\nArray of strings with option characteristics:\n- `\"BestPrice\"` - best price\n- `\"BestPriceDirect\"` - best price direct flight\n- `\"BestPriceTravelPolicy\"` - best price within travel policy\n- `\"BestPriceCorporateTariff\"` - best price corporate tariff\n- `\"Convenience\"` - convenient option\n- `\"MinTime\"` - minimum travel time\n\n### miniRules[] - Fare Rules\n\n```json\n{\n  \"$id\": \"string\",\n  \"category\": integer,            // Rule category (31, 33)\n  \"monetaryAmount\": integer,      // Penalty amount\n  \"statusInfos\": boolean,         // Rule status\n  \"currencyCode\": \"string\"        // Penalty currency\n}\n```\n\n### pricingInfo[] - Detailed Pricing Information\n\n```json\n{\n  \"$id\": \"string\",\n  \"passengerType\": integer,       // Passenger type (0 - adult)\n  \"price\": number,                // Price\n  \"taxes\": number,                // Taxes\n  \"passengerCount\": integer,      // Number of passengers\n  \"selfPaid\": boolean,            // Self-paid\n  \"isAccessTP\": boolean,          // Travel policy compliance\n  \"faresInfo\": [...]              // Fare information\n}\n```\n\n### faresInfo[] - Fare Information\n\n```json\n{\n  \"$id\": \"string\",\n  \"ticketDesignator\": \"string\",   // Fare designator (can be null)\n  \"class\": \"string\",              // Booking class (\"Y\", \"C\", \"F\")\n  \"cabinClass\": integer,          // Service class (1=economy, 2=business, 4=premium)\n  \"seatsAvailable\": integer,      // Available seats\n  \"fareFamilyKey\": \"string\",      // Fare family key\n  \"baggageAllowance\": {           // Baggage allowance\n    \"$id\": \"string\",\n    \"quantity\": integer,          // Baggage quantity/weight\n    \"type\": integer,              // Measurement type\n    \"weightMeasurementType\": integer\n  },\n  \"applyToSegmentIds\": [...]      // Segment IDs where fare applies\n}\n```\n\n=== SAMPLE JSON PEEK ===\nSample JSON file: raw/99d7fb3f49c642f0b4d45d2156271d56.json\nJSON keys: ['$id', 'metadata', 'personalData', 'routeData', 'data', 'ranker_id', 'request_time']\nJSON structure preview: {'$id': '1', 'metadata': {'$id': '2', 'searchType': 1}, 'personalData': {'$id': '3', 'profileId': 2384236, 'sex': True, 'bySelf': True, 'yearOfBirth': 1980, 'nationality': 36, 'companyID': 40253, 'isVip': True, 'hasAssistant': False, 'isGlobal': False, 'frequentFlyer': 'SU'}, 'routeData': {'$id': '4', 'requestDate': '2024-08-27T11:43:41', 'searchRoute': 'LEDMOW', 'requestDepartureDate': '2024-09-23T00:00:00'}, 'data': {'$id': '5', '$values': [{'$id': '6', 'id': '8870CDDD991E33B06782A7DCF25526F2'...\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def create_recommendation_features(train_df):\n    \"\"\"\n    Create features for recommendation system using only parquet data\n    \"\"\"\n    df_features = train_df.copy()\n    \n    # Identify potential user/item columns\n    print(\"Available columns:\", df_features.columns.tolist())\n    \n    # Basic feature engineering based on common RecSys patterns\n    # Check if we have user_id column (or similar)\n    user_cols = [col for col in df_features.columns if 'user' in col.lower()]\n    item_cols = [col for col in df_features.columns if any(x in col.lower() for x in ['item', 'product', 'movie', 'book', 'song'])]\n    rating_cols = [col for col in df_features.columns if any(x in col.lower() for x in ['rating', 'score', 'target'])]\n    \n    print(f\"Detected user columns: {user_cols}\")\n    print(f\"Detected item columns: {item_cols}\")\n    print(f\"Detected rating columns: {rating_cols}\")\n    \n    # User-based features\n    if user_cols:\n        user_col = user_cols[0]  # Fix: Take first element, not the list\n        target_col = rating_cols[0] if rating_cols else df_features.columns[-1]  # Fix: Take first element\n        \n        user_stats = df_features.groupby(user_col).agg({\n            target_col: ['count', 'mean', 'std', 'min', 'max']\n        }).reset_index()\n        user_stats.columns = [user_col] + [f'user_{stat}' for stat in ['count', 'mean', 'std', 'min', 'max']]\n        df_features = df_features.merge(user_stats, on=user_col, how='left')\n        print(f\"Added user-based features for column: {user_col}\")\n    \n    # Item-based features\n    if item_cols:\n        item_col = item_cols[0]  # Fix: Take first element, not the list\n        target_col = rating_cols[0] if rating_cols else df_features.columns[-1]  # Fix: Take first element\n        \n        item_stats = df_features.groupby(item_col).agg({\n            target_col: ['count', 'mean', 'std', 'min', 'max']\n        }).reset_index()\n        item_stats.columns = [item_col] + [f'item_{stat}' for stat in ['count', 'mean', 'std', 'min', 'max']]\n        df_features = df_features.merge(item_stats, on=item_col, how='left')\n        print(f\"Added item-based features for column: {item_col}\")\n    \n    # Additional time-based features if timestamp exists\n    timestamp_cols = [col for col in df_features.columns if any(x in col.lower() for x in ['time', 'date', 'timestamp'])]\n    if timestamp_cols:\n        timestamp_col = timestamp_cols[0]  # Fix: Take first element, not the list\n        try:\n            df_features[timestamp_col] = pd.to_datetime(df_features[timestamp_col])\n            df_features['hour'] = df_features[timestamp_col].dt.hour\n            df_features['day_of_week'] = df_features[timestamp_col].dt.dayofweek\n            df_features['month'] = df_features[timestamp_col].dt.month\n            print(f\"Added time-based features for column: {timestamp_col}\")\n        except Exception as e:\n            print(f\"Could not convert {timestamp_col} to datetime: {e}\")\n    \n    return df_features\n\n# Apply feature engineering\ntrain_features = create_recommendation_features(train_df)\nprint(f\"Enhanced train features shape: {train_features.shape}\")\nprint(\"New columns added:\", [col for col in train_features.columns if col not in train_df.columns])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:54:24.667346Z","iopub.execute_input":"2025-06-22T09:54:24.667641Z","iopub.status.idle":"2025-06-22T09:54:41.299668Z","shell.execute_reply.started":"2025-06-22T09:54:24.667618Z","shell.execute_reply":"2025-06-22T09:54:41.295253Z"}},"outputs":[{"name":"stdout","text":"Available columns: ['Id', 'bySelf', 'companyID', 'corporateTariffCode', 'frequentFlyer', 'nationality', 'isAccess3D', 'isVip', 'legs0_arrivalAt', 'legs0_departureAt', 'legs0_duration', 'legs0_segments0_aircraft_code', 'legs0_segments0_arrivalTo_airport_city_iata', 'legs0_segments0_arrivalTo_airport_iata', 'legs0_segments0_baggageAllowance_quantity', 'legs0_segments0_baggageAllowance_weightMeasurementType', 'legs0_segments0_cabinClass', 'legs0_segments0_departureFrom_airport_iata', 'legs0_segments0_duration', 'legs0_segments0_flightNumber', 'legs0_segments0_marketingCarrier_code', 'legs0_segments0_operatingCarrier_code', 'legs0_segments0_seatsAvailable', 'legs0_segments1_aircraft_code', 'legs0_segments1_arrivalTo_airport_city_iata', 'legs0_segments1_arrivalTo_airport_iata', 'legs0_segments1_baggageAllowance_quantity', 'legs0_segments1_baggageAllowance_weightMeasurementType', 'legs0_segments1_cabinClass', 'legs0_segments1_departureFrom_airport_iata', 'legs0_segments1_duration', 'legs0_segments1_flightNumber', 'legs0_segments1_marketingCarrier_code', 'legs0_segments1_operatingCarrier_code', 'legs0_segments1_seatsAvailable', 'legs0_segments2_aircraft_code', 'legs0_segments2_arrivalTo_airport_city_iata', 'legs0_segments2_arrivalTo_airport_iata', 'legs0_segments2_baggageAllowance_quantity', 'legs0_segments2_baggageAllowance_weightMeasurementType', 'legs0_segments2_cabinClass', 'legs0_segments2_departureFrom_airport_iata', 'legs0_segments2_duration', 'legs0_segments2_flightNumber', 'legs0_segments2_marketingCarrier_code', 'legs0_segments2_operatingCarrier_code', 'legs0_segments2_seatsAvailable', 'legs0_segments3_aircraft_code', 'legs0_segments3_arrivalTo_airport_city_iata', 'legs0_segments3_arrivalTo_airport_iata', 'legs0_segments3_baggageAllowance_quantity', 'legs0_segments3_baggageAllowance_weightMeasurementType', 'legs0_segments3_cabinClass', 'legs0_segments3_departureFrom_airport_iata', 'legs0_segments3_duration', 'legs0_segments3_flightNumber', 'legs0_segments3_marketingCarrier_code', 'legs0_segments3_operatingCarrier_code', 'legs0_segments3_seatsAvailable', 'legs1_arrivalAt', 'legs1_departureAt', 'legs1_duration', 'legs1_segments0_aircraft_code', 'legs1_segments0_arrivalTo_airport_city_iata', 'legs1_segments0_arrivalTo_airport_iata', 'legs1_segments0_baggageAllowance_quantity', 'legs1_segments0_baggageAllowance_weightMeasurementType', 'legs1_segments0_cabinClass', 'legs1_segments0_departureFrom_airport_iata', 'legs1_segments0_duration', 'legs1_segments0_flightNumber', 'legs1_segments0_marketingCarrier_code', 'legs1_segments0_operatingCarrier_code', 'legs1_segments0_seatsAvailable', 'legs1_segments1_aircraft_code', 'legs1_segments1_arrivalTo_airport_city_iata', 'legs1_segments1_arrivalTo_airport_iata', 'legs1_segments1_baggageAllowance_quantity', 'legs1_segments1_baggageAllowance_weightMeasurementType', 'legs1_segments1_cabinClass', 'legs1_segments1_departureFrom_airport_iata', 'legs1_segments1_duration', 'legs1_segments1_flightNumber', 'legs1_segments1_marketingCarrier_code', 'legs1_segments1_operatingCarrier_code', 'legs1_segments1_seatsAvailable', 'legs1_segments2_aircraft_code', 'legs1_segments2_arrivalTo_airport_city_iata', 'legs1_segments2_arrivalTo_airport_iata', 'legs1_segments2_baggageAllowance_quantity', 'legs1_segments2_baggageAllowance_weightMeasurementType', 'legs1_segments2_cabinClass', 'legs1_segments2_departureFrom_airport_iata', 'legs1_segments2_duration', 'legs1_segments2_flightNumber', 'legs1_segments2_marketingCarrier_code', 'legs1_segments2_operatingCarrier_code', 'legs1_segments2_seatsAvailable', 'legs1_segments3_aircraft_code', 'legs1_segments3_arrivalTo_airport_city_iata', 'legs1_segments3_arrivalTo_airport_iata', 'legs1_segments3_baggageAllowance_quantity', 'legs1_segments3_baggageAllowance_weightMeasurementType', 'legs1_segments3_cabinClass', 'legs1_segments3_departureFrom_airport_iata', 'legs1_segments3_duration', 'legs1_segments3_flightNumber', 'legs1_segments3_marketingCarrier_code', 'legs1_segments3_operatingCarrier_code', 'legs1_segments3_seatsAvailable', 'miniRules0_monetaryAmount', 'miniRules0_percentage', 'miniRules0_statusInfos', 'miniRules1_monetaryAmount', 'miniRules1_percentage', 'miniRules1_statusInfos', 'pricingInfo_isAccessTP', 'pricingInfo_passengerCount', 'profileId', 'ranker_id', 'requestDate', 'searchRoute', 'sex', 'taxes', 'totalPrice', 'selected']\nDetected user columns: []\nDetected item columns: []\nDetected rating columns: ['legs0_segments0_operatingCarrier_code', 'legs0_segments1_operatingCarrier_code', 'legs0_segments2_operatingCarrier_code', 'legs0_segments3_operatingCarrier_code', 'legs1_segments0_operatingCarrier_code', 'legs1_segments1_operatingCarrier_code', 'legs1_segments2_operatingCarrier_code', 'legs1_segments3_operatingCarrier_code']\nAdded time-based features for column: requestDate\nEnhanced train features shape: (18145372, 129)\nNew columns added: ['hour', 'day_of_week', 'month']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def preprocess_features(df):\n    \"\"\"\n    Handle missing values and encode categorical variables\n    \"\"\"\n    df_processed = df.copy()\n    \n    # Fill missing values\n    numeric_columns = df_processed.select_dtypes(include=[np.number]).columns\n    categorical_columns = df_processed.select_dtypes(include=['object']).columns\n    \n    print(f\"Numeric columns: {len(numeric_columns)}\")\n    print(f\"Categorical columns: {len(categorical_columns)}\")\n    \n    for col in numeric_columns:\n        if df_processed[col].isnull().sum() > 0:\n            df_processed[col].fillna(df_processed[col].median(), inplace=True)\n            print(f\"Filled {col} missing values with median\")\n    \n    # Encode categorical variables\n    label_encoders = {}\n    for col in categorical_columns:\n        if df_processed[col].isnull().sum() > 0:\n            df_processed[col].fillna(df_processed[col].mode()[0] if len(df_processed[col].mode()) > 0 else 'unknown', inplace=True)\n        \n        le = LabelEncoder()\n        df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n        label_encoders[col] = le\n        print(f\"Encoded categorical column: {col}\")\n    \n    return df_processed, label_encoders\n\n# Apply preprocessing\ntrain_processed, encoders = preprocess_features(train_features)\nprint(f\"Processed train shape: {train_processed.shape}\")\nprint(\"Preprocessing completed!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T09:54:53.102356Z","iopub.execute_input":"2025-06-22T09:54:53.102673Z","iopub.status.idle":"2025-06-22T10:00:56.590325Z","shell.execute_reply.started":"2025-06-22T09:54:53.102646Z","shell.execute_reply":"2025-06-22T10:00:56.586151Z"}},"outputs":[{"name":"stdout","text":"Numeric columns: 51\nCategorical columns: 73\nFilled corporateTariffCode missing values with median\nFilled legs0_segments0_baggageAllowance_quantity missing values with median\nFilled legs0_segments0_baggageAllowance_weightMeasurementType missing values with median\nFilled legs0_segments0_seatsAvailable missing values with median\nFilled legs0_segments1_baggageAllowance_quantity missing values with median\nFilled legs0_segments1_baggageAllowance_weightMeasurementType missing values with median\nFilled legs0_segments1_cabinClass missing values with median\nFilled legs0_segments1_seatsAvailable missing values with median\nFilled legs0_segments2_baggageAllowance_quantity missing values with median\nFilled legs0_segments2_baggageAllowance_weightMeasurementType missing values with median\nFilled legs0_segments2_cabinClass missing values with median\nFilled legs0_segments2_seatsAvailable missing values with median\nFilled legs0_segments3_baggageAllowance_quantity missing values with median\nFilled legs0_segments3_baggageAllowance_weightMeasurementType missing values with median\nFilled legs0_segments3_cabinClass missing values with median\nFilled legs0_segments3_seatsAvailable missing values with median\nFilled legs1_segments0_baggageAllowance_quantity missing values with median\nFilled legs1_segments0_baggageAllowance_weightMeasurementType missing values with median\nFilled legs1_segments0_cabinClass missing values with median\nFilled legs1_segments0_seatsAvailable missing values with median\nFilled legs1_segments1_baggageAllowance_quantity missing values with median\nFilled legs1_segments1_baggageAllowance_weightMeasurementType missing values with median\nFilled legs1_segments1_cabinClass missing values with median\nFilled legs1_segments1_seatsAvailable missing values with median\nFilled legs1_segments2_baggageAllowance_quantity missing values with median\nFilled legs1_segments2_baggageAllowance_weightMeasurementType missing values with median\nFilled legs1_segments2_cabinClass missing values with median\nFilled legs1_segments2_seatsAvailable missing values with median\nFilled legs1_segments3_baggageAllowance_quantity missing values with median\nFilled legs1_segments3_baggageAllowance_weightMeasurementType missing values with median\nFilled legs1_segments3_cabinClass missing values with median\nFilled legs1_segments3_seatsAvailable missing values with median\nFilled miniRules1_percentage missing values with median\nFilled miniRules1_statusInfos missing values with median\nFilled pricingInfo_isAccessTP missing values with median\nEncoded categorical column: frequentFlyer\nEncoded categorical column: legs0_arrivalAt\nEncoded categorical column: legs0_departureAt\nEncoded categorical column: legs0_duration\nEncoded categorical column: legs0_segments0_aircraft_code\nEncoded categorical column: legs0_segments0_arrivalTo_airport_city_iata\nEncoded categorical column: legs0_segments0_arrivalTo_airport_iata\nEncoded categorical column: legs0_segments0_departureFrom_airport_iata\nEncoded categorical column: legs0_segments0_duration\nEncoded categorical column: legs0_segments0_flightNumber\nEncoded categorical column: legs0_segments0_marketingCarrier_code\nEncoded categorical column: legs0_segments0_operatingCarrier_code\nEncoded categorical column: legs0_segments1_aircraft_code\nEncoded categorical column: legs0_segments1_arrivalTo_airport_city_iata\nEncoded categorical column: legs0_segments1_arrivalTo_airport_iata\nEncoded categorical column: legs0_segments1_departureFrom_airport_iata\nEncoded categorical column: legs0_segments1_duration\nEncoded categorical column: legs0_segments1_flightNumber\nEncoded categorical column: legs0_segments1_marketingCarrier_code\nEncoded categorical column: legs0_segments1_operatingCarrier_code\nEncoded categorical column: legs0_segments2_aircraft_code\nEncoded categorical column: legs0_segments2_arrivalTo_airport_city_iata\nEncoded categorical column: legs0_segments2_arrivalTo_airport_iata\nEncoded categorical column: legs0_segments2_departureFrom_airport_iata\nEncoded categorical column: legs0_segments2_duration\nEncoded categorical column: legs0_segments2_flightNumber\nEncoded categorical column: legs0_segments2_marketingCarrier_code\nEncoded categorical column: legs0_segments2_operatingCarrier_code\nEncoded categorical column: legs0_segments3_aircraft_code\nEncoded categorical column: legs0_segments3_arrivalTo_airport_city_iata\nEncoded categorical column: legs0_segments3_arrivalTo_airport_iata\nEncoded categorical column: legs0_segments3_departureFrom_airport_iata\nEncoded categorical column: legs0_segments3_duration\nEncoded categorical column: legs0_segments3_flightNumber\nEncoded categorical column: legs0_segments3_marketingCarrier_code\nEncoded categorical column: legs0_segments3_operatingCarrier_code\nEncoded categorical column: legs1_arrivalAt\nEncoded categorical column: legs1_departureAt\nEncoded categorical column: legs1_duration\nEncoded categorical column: legs1_segments0_aircraft_code\nEncoded categorical column: legs1_segments0_arrivalTo_airport_city_iata\nEncoded categorical column: legs1_segments0_arrivalTo_airport_iata\nEncoded categorical column: legs1_segments0_departureFrom_airport_iata\nEncoded categorical column: legs1_segments0_duration\nEncoded categorical column: legs1_segments0_flightNumber\nEncoded categorical column: legs1_segments0_marketingCarrier_code\nEncoded categorical column: legs1_segments0_operatingCarrier_code\nEncoded categorical column: legs1_segments1_aircraft_code\nEncoded categorical column: legs1_segments1_arrivalTo_airport_city_iata\nEncoded categorical column: legs1_segments1_arrivalTo_airport_iata\nEncoded categorical column: legs1_segments1_departureFrom_airport_iata\nEncoded categorical column: legs1_segments1_duration\nEncoded categorical column: legs1_segments1_flightNumber\nEncoded categorical column: legs1_segments1_marketingCarrier_code\nEncoded categorical column: legs1_segments1_operatingCarrier_code\nEncoded categorical column: legs1_segments2_aircraft_code\nEncoded categorical column: legs1_segments2_arrivalTo_airport_city_iata\nEncoded categorical column: legs1_segments2_arrivalTo_airport_iata\nEncoded categorical column: legs1_segments2_departureFrom_airport_iata\nEncoded categorical column: legs1_segments2_duration\nEncoded categorical column: legs1_segments2_flightNumber\nEncoded categorical column: legs1_segments2_marketingCarrier_code\nEncoded categorical column: legs1_segments2_operatingCarrier_code\nEncoded categorical column: legs1_segments3_aircraft_code\nEncoded categorical column: legs1_segments3_arrivalTo_airport_city_iata\nEncoded categorical column: legs1_segments3_arrivalTo_airport_iata\nEncoded categorical column: legs1_segments3_departureFrom_airport_iata\nEncoded categorical column: legs1_segments3_duration\nEncoded categorical column: legs1_segments3_flightNumber\nEncoded categorical column: legs1_segments3_marketingCarrier_code\nEncoded categorical column: legs1_segments3_operatingCarrier_code\nEncoded categorical column: ranker_id\nEncoded categorical column: searchRoute\nProcessed train shape: (18145372, 129)\nPreprocessing completed!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Prepare features and target\n# Identify target column based on sample_submission\ntarget_col = sample_submission.columns[-1]  # Usually the last column is target\nif target_col not in train_processed.columns:\n    # If target column name doesn't match, use the last column of train data\n    target_col = train_processed.columns[-1]\n\nprint(f\"Target column: {target_col}\")\n\n# Prepare feature columns\nfeature_cols = [col for col in train_processed.columns if col != target_col]\nprint(f\"Number of features: {len(feature_cols)}\")\n\n# Check if we have valid features and target\nif len(feature_cols) == 0:\n    print(\"No feature columns found! Using all columns except the last one as features\")\n    feature_cols = train_processed.columns[:-1].tolist()\n    target_col = train_processed.columns[-1]\n\nX = train_processed[feature_cols]\ny = train_processed[target_col]\n\nprint(f\"Features shape: {X.shape}\")\nprint(f\"Target shape: {y.shape}\")\nprint(f\"Target statistics: {y.describe()}\")\n\n# Train-validation split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(f\"Training set: {X_train.shape}\")\nprint(f\"Validation set: {X_val.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T10:01:54.645203Z","iopub.execute_input":"2025-06-22T10:01:54.645491Z","iopub.status.idle":"2025-06-22T10:02:43.734702Z","shell.execute_reply.started":"2025-06-22T10:01:54.645467Z","shell.execute_reply":"2025-06-22T10:02:43.730124Z"}},"outputs":[{"name":"stdout","text":"Target column: selected\nNumber of features: 128\nFeatures shape: (18145372, 128)\nTarget shape: (18145372,)\nTarget statistics: count    1.814537e+07\nmean     5.816304e-03\nstd      7.604259e-02\nmin      0.000000e+00\n25%      0.000000e+00\n50%      0.000000e+00\n75%      0.000000e+00\nmax      1.000000e+00\nName: selected, dtype: float64\nTraining set: (14516297, 128)\nValidation set: (3629075, 128)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Check data types and identify problematic columns\nprint(\"Checking data types:\")\nprint(X_train.dtypes)\nprint(\"\\nProblematic columns:\")\ndatetime_cols = X_train.select_dtypes(include=['datetime64']).columns\nprint(\"Datetime columns:\", datetime_cols.tolist())\n\n# Fix datetime columns by converting to numeric\ndef fix_datetime_columns(df):\n    \"\"\"Convert datetime columns to numeric format\"\"\"\n    df_fixed = df.copy()\n    \n    # Convert datetime columns to timestamp (numeric)\n    datetime_cols = df_fixed.select_dtypes(include=['datetime64']).columns\n    for col in datetime_cols:\n        print(f\"Converting datetime column: {col}\")\n        # Convert to timestamp (seconds since epoch)\n        df_fixed[col] = pd.to_datetime(df_fixed[col]).astype('int64') // 10**9\n        \n    # Ensure all columns are numeric\n    for col in df_fixed.columns:\n        if df_fixed[col].dtype == 'object':\n            print(f\"Converting object column to numeric: {col}\")\n            df_fixed[col] = pd.to_numeric(df_fixed[col], errors='coerce')\n            df_fixed[col].fillna(0, inplace=True)\n    \n    return df_fixed\n\n# Apply fixes to training and validation data\nX_train_fixed = fix_datetime_columns(X_train)\nX_val_fixed = fix_datetime_columns(X_val)\n\nprint(\"Fixed data types:\")\nprint(X_train_fixed.dtypes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T10:03:08.52573Z","iopub.execute_input":"2025-06-22T10:03:08.526031Z","iopub.status.idle":"2025-06-22T10:03:23.10415Z","shell.execute_reply.started":"2025-06-22T10:03:08.525993Z","shell.execute_reply":"2025-06-22T10:03:23.099452Z"}},"outputs":[{"name":"stdout","text":"Checking data types:\nId                       int64\nbySelf                    bool\ncompanyID                int64\ncorporateTariffCode      Int64\nfrequentFlyer            int64\n                        ...   \ntaxes                  float64\ntotalPrice             float64\nhour                     int32\nday_of_week              int32\nmonth                    int32\nLength: 128, dtype: object\n\nProblematic columns:\nDatetime columns: ['requestDate']\nConverting datetime column: requestDate\nConverting datetime column: requestDate\nFixed data types:\nId                       int64\nbySelf                    bool\ncompanyID                int64\ncorporateTariffCode      Int64\nfrequentFlyer            int64\n                        ...   \ntaxes                  float64\ntotalPrice             float64\nhour                     int32\nday_of_week              int32\nmonth                    int32\nLength: 128, dtype: object\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\n\n# LightGBM parameters\nlgb_params = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'boosting_type': 'gbdt',\n    'num_leaves': 31,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 5,\n    'verbose': -1,\n    'random_state': 42\n}\n\n# Create datasets with fixed data\ntrain_data = lgb.Dataset(X_train_fixed, label=y_train)\nval_data = lgb.Dataset(X_val_fixed, label=y_val, reference=train_data)\n\n# Train model\nprint(\"Training LightGBM model...\")\nlgb_model = lgb.train(\n    lgb_params,\n    train_data,\n    valid_sets=[train_data, val_data],\n    num_boost_round=1000,\n    callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(period=100)]\n)\n\n# Validation predictions\nval_pred = lgb_model.predict(X_val_fixed, num_iteration=lgb_model.best_iteration)\nval_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\nprint(f\"Validation RMSE: {val_rmse:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T10:04:16.888048Z","iopub.execute_input":"2025-06-22T10:04:16.888344Z","iopub.status.idle":"2025-06-22T10:09:51.090044Z","shell.execute_reply.started":"2025-06-22T10:04:16.888321Z","shell.execute_reply":"2025-06-22T10:09:51.086189Z"}},"outputs":[{"name":"stdout","text":"Training LightGBM model...\nTraining until validation scores don't improve for 50 rounds\n[100]\ttraining's rmse: 0.0722821\tvalid_1's rmse: 0.0730894\n[200]\ttraining's rmse: 0.0715862\tvalid_1's rmse: 0.0724908\n[300]\ttraining's rmse: 0.0711732\tvalid_1's rmse: 0.0721693\n[400]\ttraining's rmse: 0.0708773\tvalid_1's rmse: 0.0719605\n[500]\ttraining's rmse: 0.0706229\tvalid_1's rmse: 0.0717884\n[600]\ttraining's rmse: 0.0703964\tvalid_1's rmse: 0.0716369\n[700]\ttraining's rmse: 0.070217\tvalid_1's rmse: 0.0715278\n[800]\ttraining's rmse: 0.0700387\tvalid_1's rmse: 0.0714254\n[900]\ttraining's rmse: 0.0698797\tvalid_1's rmse: 0.0713313\n[1000]\ttraining's rmse: 0.0697463\tvalid_1's rmse: 0.0712661\nDid not meet early stopping. Best iteration is:\n[1000]\ttraining's rmse: 0.0697463\tvalid_1's rmse: 0.0712661\nValidation RMSE: 0.0713\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Create test features based on sample_submission structure\nprint(\"Preparing test data...\")\n\n# Check sample_submission structure\nprint(\"Sample submission columns:\", sample_submission.columns.tolist())\nprint(\"Sample submission shape:\", sample_submission.shape)\n\n# Method 1: If sample_submission contains features\nif len(sample_submission.columns) > 1:\n    # Extract features from sample_submission (excluding target column)\n    test_features = sample_submission.drop(columns=[sample_submission.columns[-1]])\n    \n    # Apply same feature engineering as training data\n    print(\"Applying feature engineering to test data...\")\n    test_enhanced = create_recommendation_features(test_features)\n    \n    # Apply same preprocessing\n    test_processed = test_enhanced.copy()\n    \n    # Handle categorical encoding for test data\n    categorical_columns = test_processed.select_dtypes(include=['object']).columns\n    for col in categorical_columns:\n        if col in encoders:\n            test_processed[col] = test_processed[col].astype(str)\n            # Handle unseen categories\n            unseen_mask = ~test_processed[col].isin(encoders[col].classes_)\n            if unseen_mask.any():\n                test_processed.loc[unseen_mask, col] = encoders[col].classes_[0]\n            test_processed[col] = encoders[col].transform(test_processed[col])\n    \n    # Fill missing values\n    numeric_columns = test_processed.select_dtypes(include=[np.number]).columns\n    for col in numeric_columns:\n        if test_processed[col].isnull().sum() > 0:\n            test_processed[col].fillna(test_processed[col].median(), inplace=True)\n    \n    # Ensure test data has same features as training data\n    missing_cols = set(feature_cols) - set(test_processed.columns)\n    for col in missing_cols:\n        test_processed[col] = 0\n    \n    # Select and reorder columns to match training features\n    test_processed = test_processed[feature_cols]\n    \n    print(f\"Test data shape after preprocessing: {test_processed.shape}\")\n    \n    # Generate predictions\n    test_pred = lgb_model.predict(test_processed, num_iteration=lgb_model.best_iteration)\n    \nelse:\n    # Method 2: If sample_submission only has ID and target columns\n    print(\"Sample submission appears to only have ID and target columns\")\n    print(\"You may need to create test features based on your competition requirements\")\n    \n    # Placeholder - replace with actual test data preparation logic\n    test_pred = np.random.random(len(sample_submission))\n    print(\"Using placeholder predictions - replace with actual test data logic\")\n\nprint(f\"Generated {len(test_pred)} test predictions\")\nprint(f\"Prediction statistics: min={test_pred.min():.4f}, max={test_pred.max():.4f}, mean={test_pred.mean():.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T10:09:51.093089Z","iopub.execute_input":"2025-06-22T10:09:51.093348Z","iopub.status.idle":"2025-06-22T10:10:07.575433Z","shell.execute_reply.started":"2025-06-22T10:09:51.093324Z","shell.execute_reply":"2025-06-22T10:10:07.57104Z"}},"outputs":[{"name":"stdout","text":"Preparing test data...\nSample submission columns: ['Id', 'ranker_id', 'selected']\nSample submission shape: (6897776, 3)\nApplying feature engineering to test data...\nAvailable columns: ['Id', 'ranker_id']\nDetected user columns: []\nDetected item columns: []\nDetected rating columns: []\nTest data shape after preprocessing: (6897776, 128)\nGenerated 6897776 test predictions\nPrediction statistics: min=0.5281, max=0.5281, mean=0.5281\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Create submission file\nsubmission = sample_submission.copy()\nsubmission[submission.columns[-1]] = test_pred\n\n# Apply post-processing if needed\n# For example, if predictions should be within a certain range:\nif 'rating' in submission.columns[-1].lower():\n    submission[submission.columns[-1]] = np.clip(submission[submission.columns[-1]], 1, 5)\n    print(\"Clipped predictions to rating range [1, 5]\")\n\nprint(\"Submission preview:\")\nprint(submission.head(10))\nprint(f\"\\nSubmission shape: {submission.shape}\")\nprint(f\"Final prediction statistics:\")\nprint(submission[submission.columns[-1]].describe())\n\n# Save submission files\nsubmission.to_parquet('submission.parquet', index=False)\nsubmission.to_csv('submission.csv', index=False)\n\nprint(\"Submission saved as 'submission.parquet' and 'submission.csv'\")\nprint(\"Ready for upload to Kaggle!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T10:15:17.404382Z","iopub.execute_input":"2025-06-22T10:15:17.404701Z","iopub.status.idle":"2025-06-22T10:15:37.220952Z","shell.execute_reply.started":"2025-06-22T10:15:17.404659Z","shell.execute_reply":"2025-06-22T10:15:37.216374Z"}},"outputs":[{"name":"stdout","text":"Submission preview:\n                Id                         ranker_id  selected\n18144679  18144679  c9373e5f772e43d593dd6ad2fa90f67a  0.528131\n18144680  18144680  c9373e5f772e43d593dd6ad2fa90f67a  0.528131\n18144681  18144681  c9373e5f772e43d593dd6ad2fa90f67a  0.528131\n18144682  18144682  c9373e5f772e43d593dd6ad2fa90f67a  0.528131\n18144683  18144683  c9373e5f772e43d593dd6ad2fa90f67a  0.528131\n18144684  18144684  c9373e5f772e43d593dd6ad2fa90f67a  0.528131\n18144685  18144685  c9373e5f772e43d593dd6ad2fa90f67a  0.528131\n18144686  18144686  c9373e5f772e43d593dd6ad2fa90f67a  0.528131\n18144687  18144687  c9373e5f772e43d593dd6ad2fa90f67a  0.528131\n18144688  18144688  c9373e5f772e43d593dd6ad2fa90f67a  0.528131\n\nSubmission shape: (6897776, 3)\nFinal prediction statistics:\ncount    6.897776e+06\nmean     5.281309e-01\nstd      9.992008e-15\nmin      5.281309e-01\n25%      5.281309e-01\n50%      5.281309e-01\n75%      5.281309e-01\nmax      5.281309e-01\nName: selected, dtype: float64\nSubmission saved as 'submission.parquet' and 'submission.csv'\nReady for upload to Kaggle!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}